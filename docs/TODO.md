# Tasks - TODO

## In Progress

- [ ] [Optimization] 端到端音频流延迟的性能测试和优化

## To Do

- [ ] [Frontend] **前端页面适配**:
- [ ] `GoalSetting.js`: 实现目标设置界面，支持文本输入。
- [ ] `Conversation.js`: 适配新AI角色交互逻辑（对话模式仅用于"OralTutor"）。
- [ ] [Frontend] **需求收集**:
- [ ] 在 `GoalSetting.js` 中集成文本输入组件，收集用户口语练习的具体需求（场景、话题、侧重点）。
- [ ] 确保收集到的需求数据结构化，便于后续传递给AI。
- [ ] [Frontend] Integration: Verify the new Role Switching and Barge-in logic in `Conversation.js`.
- [ ] [Backend] **Conversation State**: Implement `conversation-service` to persist chat history and state across sessions.
- [ ] [Backend] **Media Processing**: Connect `media-processing-service` for saving audio session archives.
- [ ] [Optimization] 端到端音频流延迟的性能测试和优化
- [ ] [Optimization] 实现音频流缓冲和网络自适应机制
- [ ] [Monitoring] 添加服务健康监控和告警
- [ ] [Monitoring] 实现用户行为分析和性能指标收集
- [ ] [Security] 增强 API 安全性和用户数据保护
- [ ] [Docs] 更新 user_service/docs/schema.md 文档以对齐数据库表结构
- [ ] [Docs] 编写 API 文档和使用指南
- [ ] [Deployment] 完善 Docker Compose 部署配置
- [ ] [Deployment] 实现 CI/CD 流水线自动化
- [ ] [Testing] 编写完整的集成测试套件

## Backlog

- [ ] [Frontend] 添加多语言界面支持

## Done

- [x] [Backend] **Bug Fixes & Logic Refinements**:
- [x] **500 Error Fix**: Resolved `user-service` 500 error by defaulting undefined `type`/`description` fields to null in `createGoal`.
- [x] **Interruption Handling**: Implemented server-side logic in `ai-omni-service` to ignore response events for interrupted turns.
- [x] **JSON Suppression**: Implemented text stream filtering to hide JSON action blocks from the client UI.
- [x] **Bilingual Logic**: Implemented dynamic language strategy in `OralTutor` (Immersion for Japanese, Bridge Mode for others).
- [x] [Backend] **InfoCollector**: Verified functional via `test_client_scenario.py` (correctly switches role and collects data).
- [x] [Frontend] **Onboarding**: Implemented Native Language selection in `Onboarding.js` and connected to backend API.
- [x] [AI Engine] **Prompt Engineering**: Updated `InfoCollector` prompt to dynamically use the user's native language.
- [x] [Testing] **Interruption**: Implemented "User Interruption" logic in `test_client_scenario.py` (Mutes playback + Auto-Record, Fixed double-Enter bug).
- [x] [Testing] **Debug & Stability**:
- [x] Fixed `ai-omni-service` crash caused by malformed JSON from LLM (improved regex/parsing).
- [x] Implemented auto-reconnection logic in `ai-omni-service` to handle DashScope timeouts/disconnections.
- [x] Fixed `OSError: [Errno -9988] Stream closed` in `test_client_scenario.py` by implementing safe mute/unmute logic instead of closing streams.
- [x] Fixed infinite error loop in `ai-omni-service` when WebSocket connection closes.
- [x] Updated `test_client.py`: Fixed duplicate role labels, implemented microphone muting during TTS playback, and improved reconnection logic.
- [x] **[Feature] Interactive Test Client**: Refactored `test_client_scenario.py` to support real-time audio input with Manual Commit (Enter key) mode.
- [x] **[Feature] Manual Turn-Taking**: Disabled Server-side VAD in `ai-omni-service` to allow client-controlled response triggering via `user_audio_ended` event.
- [x] **[Debug] Audio Payload Fix**: Resolved `audio_stream` payload structure mismatch between `comms-service` and `ai-omni-service`.
- [x] **[Optimization] Prompt Engineering**: Enhanced `InfoCollector` prompt to ask for learning challenges and merge them into `interests`.
- [x] [Frontend] Refactor Conversation.js to use WebSocket for text messages instead of HTTP API.
- [x] [Frontend] Move WebSocket management from RealTimeRecorder to Conversation.js.
- [x] [Infrastructure] Fix Nginx configuration for comms-service upstream port (8080) and WS path (/api/ws/).
- [x] **Phase 1: Foundation & Core Services**
- [x] 5. [Backend] Create Real-time Comms Layer: Setup WebSocket server.
- [x] 4. [Backend] Setup API Gateway: Configure routing for User Service.
- [x] [Architecture] Redesign AI Engine to support both pipelined (ASR+LLM+TTS) and unified multimodal models.
- [x] 1. [Data Persistence] Setup PostgreSQL/MongoDB and Redis instances.
- [x] 2. [Data Persistence] Define database schemas for User, Conversation, etc.
- [x] 3. [Backend] Create User Service: Implement user registration, login, JWT auth.
- [x] [Test] Verify JWT end-to-end authentication and session creation flow via temporary HTTP endpoint.
- [x] [Debug] Fixed 'ws' server 'connection' event not firing by changing base image to node:18-slim.
- [x] **Phase 2: AI Integration & Core Logic**
- [x] 6. [Backend] Create AI Service Layer (AI Engine): Abstract ASR/LLM/TTS interfaces.
- [x] 7. [AI Engine] Design and implement a Prompt Management module to dynamically construct prompts using user profile, conversation history, and learning goals.
- [x] 8.[Backend] Integrate a mocked or preliminary AI service for initial testing.
- [x] 9.[Backend] Create Conversation Service: Manage conversation state and orchestrate calls between Comms Layer and AI Layer.
- [x] 10.[API Gateway] Add routing for WebSocket connections and Conversation Service.
- [x] 11. [Frontend] Scaffold React/Mobile client application.
- [x] 12. [Frontend] Implement user authentication flow (login/register pages).
- [x] [Debug] Resolve persistent HMR WebSocket connection issue in proxy environment.
- [x] **Phase 3: Client-side Development**
- [x] 13. [Frontend] Implement real-time audio capture using AudioWorklet.
- [x] 14. [Frontend] Implement WebSocket connection to the backend.
- [x] 15. [Frontend] Implement audio streaming to the backend and playback of received audio.
- [x] [AI Engine] Create a new `azureAiService.js` in `ai-service` to manage the Azure AI Voice Live API connection.
- [x] [AI Engine] Implement WebSocket connection logic to the Azure AI endpoint within `azureAiService.js`.
- [x] [AI Engine] Handle the real-time audio stream from `comms-service` and forward it to the Azure AI service.
- [x] [AI Engine] Integrate `azureAiService.js` into the main `ai-service` logic to replace the mock service.
- [x] [AI Engine] Process real-time responses (audio and text) from Azure AI and forward them back to the client via `comms-service`.
- [x] [AI Engine] Implement real-time TTS (Text-to-Speech) audio streaming from Azure AI to the client via comms-service.
- [x] [Frontend] Fix ASR text not displaying in conversation history.
- [x] [AI Engine] Replace Azure AI Service with Qwen3-Omni multimodal AI engine.
- [x] **Phase 4: Qwen3-Omni Integration**
- [x] [AI Engine] Create omni-service microservice with Qwen3-Omni integration.
- [x] [AI Engine] Implement text processing API endpoint in omni-service.
- [x] [AI Engine] Implement audio processing API endpoint in omni-service.
- [x] [AI Engine] Implement user context management in omni-service.
- [x] [AI Engine] Implement mock mode for Qwen3-Omni engine for development and testing.
- [x] [Testing] Verify all omni-service API endpoints are functioning correctly.
- [x] [Debug] Resolve environment variable loading issues in omni-service.
- [x] [Debug] Fix model initialization problems in containerized environments.
- [x] [Architecture] Consolidate ai-service and omni-service into unified ai-omni-service.
- [x] [Docker] Update docker-compose.yml with unified ai-omni-service configuration.
- [x] [API Gateway] Refactor nginx.conf routing for consolidated AI service endpoints.
- [x] [Comms Service] Update WebSocket connection URL to point to unified ai-omni-service.
- [x] [Backend] Fix user profile API 401 error by correcting JWT token field inconsistency (id vs userId) in auth middleware and controller.
- [x] [Docs] Update GEMINI.md with client containerization configuration and directory structure.
- [x] **Phase 4: Qwen3-Omni Integration & Python Migration**
- [x] [Architecture] Migrate `ai-omni-service` from Node.js to Python (FastAPI + Uvicorn).
- [x] [AI Engine] Integrate `dashscope` Python SDK (`OmniRealtimeConversation`).
- [x] [AI Engine] Implement `PromptManager` for dynamic System Prompt generation.
- [x] [Debug] Fix `QWEN3_OMNI_API_KEY` environment variable issue in Docker.
- [x] [Debug] Fix Nginx WebSocket proxy configuration (path stripping and CORS).
- [x] [Debug] Fix DashScope SDK `send_text` and `update_session` errors.
- [x] [Debug] Fix "off-topic response" by passing user text as instructions.
- [x] [Debug] Correctly map DashScope response events to client protocol.
- [x] [Stability] Implement automatic reconnection logic for DashScope.
- [x] [Testing] Create `test_client.py` for multi-turn testing.
- [x] [Frontend] 将前端 React 应用对接新的 Python ai-omni-service WebSocket 协议。
- [x] [AI Engine] 优化音频流处理，处理来自前端的实时 PCM 流并转发给 DashScope。
- [x] [Frontend] 优化音频录制和播放的用户体验
- [x] [Backend] Investigate and implement User Transcription event handling in Python AI Service (DashScope)
- [x] [Frontend] 实现对话历史管理界面
- [x] [Frontend] 忽略对话历史中的空消息
- [x] [Frontend] 实现响应式设计适配移动端
- [x] [Backend] 完成用户服务 API 端点测试（登录、更新等）
- [x] [Backend] 添加会话管理和权限控制
- [x] [Backend] 创建历史与分析服务：实现对话的异步存储
- [x] [Testing] 在 test_client.py 调试脚本中集成 PCM 音频输入和实时 TTS 输出功能，实现真实的音频输入输出模拟。
- [x] [AI Engine] Prompt Engineering: Optimize System Prompt for 'AI Oral Tutor' persona (correct grammar/expression over pronunciation, intelligent turn-taking).
- [x] [Backend] 创建媒体处理服务：实现音频流转码和 S3/OSS 存储
- [x] Verify the new "Oral Tutor" backend flow (Context Fetching -> Prompt Selection -> Action Execution).并通过test_client.py的对话测试（支持多轮对话、文本输入）
- [x] [AI Engine] ai-glm-service: Setup Docker environment and fix dependency network issues using local wheels strategy
- [x] [Backend] **Persistence & Persistence Fix**: Implemented message history tracking in `ai-omni-service` and integrated with `history-analytics-service` to save dialogues to MongoDB.
- [x] [Backend] **Interruption Logic Optimization**: Replaced simplistic interruption flag with `cancel_response()` call and `ignored_response_ids` filtering to prevent old audio leaks and "active response" errors while maintaining conversation context.
- [x] [Backend] **Audio Quality Fix**: Restored `base64.b64decode` in `ai-omni-service` to correctly process binary audio stream from `comms-service`.
- [x] [Testing] **Consolidation**: Optimized `test_client_scenario.py` with proper sample rates and persistence verification hints, and deleted redundant `test_client.py`.
